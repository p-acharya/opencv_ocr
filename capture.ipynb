{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5 import QtWidgets, QtCore, QtGui\n",
    "from PyQt5.QtWidgets import (QSystemTrayIcon, QApplication, QLabel, QMainWindow, QPushButton, QWidget, \n",
    "                             QVBoxLayout, QTextEdit, QDialog, QComboBox, QAction, QLineEdit, QLabel, QInputDialog)\n",
    "from PyQt5.QtGui import QIcon, QFont\n",
    "from PyQt5.QtCore import Qt, QCoreApplication, QSettings, QPoint\n",
    "import tkinter as tk\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import io\n",
    "import json\n",
    "import inspect\n",
    "import ctypes\n",
    "from io import BytesIO\n",
    "import win32clipboard\n",
    "import glob\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output, Image, display\n",
    "from google.cloud.vision import types\n",
    "from google.cloud import vision\n",
    "import mss\n",
    "import pyperclip\n",
    "import mss.tools\n",
    "import qt_utils\n",
    "from PyQt5.QtWidgets import QMessageBox\n",
    "from google.cloud import speech\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:/Users/poorv/Downloads/ocr_scripts/keys/direct-outlook-270501-c05c2d97d1c6.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_text_clipboard(text):\n",
    "    pyperclip.copy(text)\n",
    "    spam = pyperclip.paste()\n",
    "    \n",
    "def dtlh(path, lh):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    if type(path) == str:\n",
    "        with io.open(path, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "            image = vision.types.Image(content=content)\n",
    "    else:\n",
    "        image = types.Image(content=cv2.imencode('.jpg', path)[1].tostring())\n",
    "        \n",
    "    response = client.text_detection(\n",
    "    image=image,\n",
    "    image_context={\"language_hints\": lh},\n",
    "    )\n",
    "    texts = response.text_annotations\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))\n",
    "        \n",
    "        print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "    try:\n",
    "        return texts[0].description\n",
    "    except IndexError:\n",
    "        print('no text in image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class ocrWidget(QtWidgets.QWidget):\n",
    "#     clicked = QtCore.pyqtSignal(object)\n",
    "    \n",
    "    def __init__(self, parent = None, lang_hint = []):\n",
    "        super().__init__()\n",
    "        root = tk.Tk()\n",
    "        screen_width = root.winfo_screenwidth()\n",
    "        screen_height = root.winfo_screenheight()\n",
    "        self.setGeometry(0, 0, screen_width, screen_height)\n",
    "        self.setWindowTitle(' ')\n",
    "        self.lang_hint = lang_hint\n",
    "        self.begin = QtCore.QPoint()\n",
    "        self.end = QtCore.QPoint()\n",
    "        self.parent = parent\n",
    "        self.setWindowOpacity(0.3)\n",
    "        QtWidgets.QApplication.setOverrideCursor(\n",
    "            QtGui.QCursor(QtCore.Qt.CrossCursor)\n",
    "        )\n",
    "        self.setWindowFlags(QtCore.Qt.FramelessWindowHint)\n",
    "        QtWidgets.QShortcut(\n",
    "            QtGui.QKeySequence(\"Escape\"), self, activated=self.on_Escape\n",
    "        )\n",
    "\n",
    "    def paintEvent(self, event):\n",
    "        qp = QtGui.QPainter(self)\n",
    "        qp.setPen(QtGui.QPen(QtGui.QColor('black'), 3))\n",
    "        qp.setBrush(QtGui.QColor(128, 128, 255, 128))\n",
    "        qp.drawRect(QtCore.QRect(self.begin, self.end))\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        self.begin = event.pos()\n",
    "        self.end = self.begin\n",
    "        self.update()\n",
    "    \n",
    "    @QtCore.pyqtSlot()\n",
    "    def on_Escape(self):\n",
    "        print(\"main esp exit\")\n",
    "#         self.close()\n",
    "        self.closeAndReturn()\n",
    "        \n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        self.end = event.pos()\n",
    "        self.update()\n",
    "    \n",
    "    def closeAndReturn(self):\n",
    "        self.close()\n",
    "        self.parent.setWindowOpacity(1.)\n",
    "        return\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        previous = self.parent\n",
    "        self.close()\n",
    "\n",
    "        x1 = min(self.begin.x(), self.end.x())\n",
    "        y1 = min(self.begin.y(), self.end.y())\n",
    "        x2 = max(self.begin.x(), self.end.x())\n",
    "        y2 = max(self.begin.y(), self.end.y())\n",
    "        \n",
    "        if (y1 == y2 and x1 == x2):\n",
    "            print(\"no region selected\")\n",
    "            self.closeAndReturn()\n",
    "        \n",
    "        with mss.mss() as sct:\n",
    "            print(\"lang_hint:\", self.lang_hint)\n",
    "            # The screen part to capture            \n",
    "            monitor = {\"top\": y1, \"left\":x1, \"width\": abs(x2 - x1) , \"height\": abs(y2 - y1)}\n",
    "            output = \"sct-{top}x{left}_{width}x{height}.png\".format(**monitor)\n",
    "            sct_img = sct.grab(monitor)\n",
    "            try:\n",
    "                img = PIL.Image.frombytes(\"RGB\", sct_img.size, sct_img.bgra, \"raw\", \"BGRX\")\n",
    "                img = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2RGB)\n",
    "                im_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "                ret,thresh = cv2.threshold(im_gray,127,255,cv2.THRESH_BINARY_INV)\n",
    "#                 ocr = dtlh(thresh, [\"hi\"])\n",
    "                ocr = dtlh(thresh, self.lang_hint)\n",
    "                popup = False\n",
    "                if ocr:\n",
    "                    send_text_clipboard(ocr)\n",
    "                    print(ocr)\n",
    "                    if popup:\n",
    "                        msg = QMessageBox()\n",
    "                        msg.setText(ocr)\n",
    "                        msg.setWindowTitle(\"Captured Text\")\n",
    "                        msg.setFont(QFont('Arial', 20)) \n",
    "                        x = msg.exec_()  # this will show our messagebox\n",
    "                self.parent.setWindowOpacity(1.)\n",
    "            except ValueError:\n",
    "                print(\"invalid region selection. try again\")\n",
    "                self.closeAndReturn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang_hint: ['hi']\n",
      "\n",
      "\"। दावण म समुद्र क किनार काफी वषा हाता\n",
      "वों में\\nरहती है। भारत के चार प्रमुख महानगर हैं\n",
      "ट और कलकत्ता\\nपूर्वी तट के मुख्य बंदरगाह\n",
      "और चण्डीगढ़ भारत के कुछ अन्य\\nबड़े शहर हैं\n",
      "हीं रहा। यातायात के प्रमुख साधन हैं :\\nरेलगाडि\n",
      "सुन्दर मन्दिर और इमारतें हैं, जिन्हें देखने के लिं\n",
      "\"\n",
      "bounds: (-8,0),(773,0),(773,260),(-8,260)\n",
      "\n",
      "\"।\"\n",
      "bounds: (16,0),(31,0),(31,36),(16,36)\n",
      "\n",
      "\"दावण\"\n",
      "bounds: (46,0),(142,0),(142,36),(46,36)\n",
      "\n",
      "\"म\"\n",
      "bounds: (161,0),(188,0),(188,36),(161,36)\n",
      "\n",
      "\"समुद्र\"\n",
      "bounds: (203,0),(287,0),(287,36),(203,36)\n",
      "\n",
      "\"क\"\n",
      "bounds: (312,0),(339,0),(339,36),(312,36)\n",
      "\n",
      "\"किनार\"\n",
      "bounds: (362,0),(454,0),(454,36),(362,36)\n",
      "\n",
      "\"काफी\"\n",
      "bounds: (479,0),(560,0),(560,36),(479,36)\n",
      "\n",
      "\"वषा\"\n",
      "bounds: (586,0),(636,0),(636,36),(586,36)\n",
      "\n",
      "\"हाता\"\n",
      "bounds: (663,0),(722,0),(722,36),(663,36)\n",
      "\n",
      "\"वों\"\n",
      "bounds: (-7,24),(20,24),(19,73),(-8,73)\n",
      "\n",
      "\"में\"\n",
      "bounds: (38,24),(52,24),(51,73),(37,73)\n",
      "\n",
      "\"\\\"\n",
      "bounds: (67,24),(81,24),(80,73),(66,73)\n",
      "\n",
      "\"n\"\n",
      "bounds: (91,25),(105,25),(104,74),(90,74)\n",
      "\n",
      "\"रहती\"\n",
      "bounds: (110,25),(179,26),(178,75),(109,74)\n",
      "\n",
      "\"है\"\n",
      "bounds: (200,26),(223,26),(222,75),(199,75)\n",
      "\n",
      "\"।\"\n",
      "bounds: (232,26),(235,26),(234,75),(231,75)\n",
      "\n",
      "\"भारत\"\n",
      "bounds: (248,26),(349,27),(348,76),(247,75)\n",
      "\n",
      "\"के\"\n",
      "bounds: (360,28),(393,28),(392,77),(359,77)\n",
      "\n",
      "\"चार\"\n",
      "bounds: (412,28),(467,29),(466,79),(411,78)\n",
      "\n",
      "\"प्रमुख\"\n",
      "bounds: (488,29),(569,30),(568,79),(487,78)\n",
      "\n",
      "\"महानगर\"\n",
      "bounds: (588,30),(711,31),(710,80),(587,79)\n",
      "\n",
      "\"हैं\"\n",
      "bounds: (737,32),(751,32),(750,81),(736,81)\n",
      "\n",
      "\"ट\"\n",
      "bounds: (-7,70),(29,70),(29,124),(-7,124)\n",
      "\n",
      "\"और\"\n",
      "bounds: (40,70),(98,70),(98,124),(40,124)\n",
      "\n",
      "\"कलकत्ता\"\n",
      "bounds: (118,70),(246,70),(246,124),(118,124)\n",
      "\n",
      "\"\\\"\n",
      "bounds: (251,70),(266,70),(266,124),(251,124)\n",
      "\n",
      "\"n\"\n",
      "bounds: (272,71),(287,71),(287,125),(272,125)\n",
      "\n",
      "\"पूर्वी\"\n",
      "bounds: (294,71),(348,71),(348,125),(294,125)\n",
      "\n",
      "\"तट\"\n",
      "bounds: (364,71),(411,71),(411,125),(364,125)\n",
      "\n",
      "\"के\"\n",
      "bounds: (430,71),(464,71),(464,125),(430,125)\n",
      "\n",
      "\"मुख्य\"\n",
      "bounds: (483,71),(556,71),(556,126),(483,126)\n",
      "\n",
      "\"बंदरगाह\"\n",
      "bounds: (576,72),(700,72),(700,126),(576,126)\n",
      "\n",
      "\"और\"\n",
      "bounds: (-7,113),(54,113),(54,166),(-7,166)\n",
      "\n",
      "\"चण्डीगढ़\"\n",
      "bounds: (74,113),(202,114),(202,167),(74,166)\n",
      "\n",
      "\"भारत\"\n",
      "bounds: (236,114),(300,114),(300,167),(236,167)\n",
      "\n",
      "\"के\"\n",
      "bounds: (332,115),(347,115),(347,168),(332,168)\n",
      "\n",
      "\"कुछ\"\n",
      "bounds: (375,115),(439,115),(439,168),(375,168)\n",
      "\n",
      "\"अन्य\"\n",
      "bounds: (461,115),(522,115),(522,169),(461,169)\n",
      "\n",
      "\"\\\"\n",
      "bounds: (525,116),(540,116),(540,169),(525,169)\n",
      "\n",
      "\"n\"\n",
      "bounds: (552,116),(567,116),(567,169),(552,169)\n",
      "\n",
      "\"बड़े\"\n",
      "bounds: (572,116),(617,116),(617,169),(572,169)\n",
      "\n",
      "\"शहर\"\n",
      "bounds: (636,117),(708,117),(708,170),(636,170)\n",
      "\n",
      "\"हैं\"\n",
      "bounds: (728,117),(757,117),(757,170),(728,170)\n",
      "\n",
      "\"हीं\"\n",
      "bounds: (-8,162),(38,162),(38,215),(-8,215)\n",
      "\n",
      "\"रहा\"\n",
      "bounds: (55,161),(107,161),(107,214),(55,214)\n",
      "\n",
      "\"।\"\n",
      "bounds: (111,161),(120,161),(120,214),(111,214)\n",
      "\n",
      "\"यातायात\"\n",
      "bounds: (142,160),(268,159),(268,213),(142,214)\n",
      "\n",
      "\"के\"\n",
      "bounds: (287,160),(320,160),(320,213),(287,213)\n",
      "\n",
      "\"प्रमुख\"\n",
      "bounds: (348,160),(431,160),(431,213),(348,213)\n",
      "\n",
      "\"साधन\"\n",
      "bounds: (450,159),(527,159),(527,213),(450,213)\n",
      "\n",
      "\"हैं\"\n",
      "bounds: (539,159),(570,159),(570,212),(539,212)\n",
      "\n",
      "\":\"\n",
      "bounds: (581,159),(606,159),(606,212),(581,212)\n",
      "\n",
      "\"\\\"\n",
      "bounds: (619,159),(634,159),(634,212),(619,212)\n",
      "\n",
      "\"n\"\n",
      "bounds: (640,159),(655,159),(655,212),(640,212)\n",
      "\n",
      "\"रेलगाडि\"\n",
      "bounds: (654,158),(773,158),(773,211),(654,212)\n",
      "\n",
      "\"सुन्दर\"\n",
      "bounds: (12,208),(95,207),(95,259),(12,260)\n",
      "\n",
      "\"मन्दिर\"\n",
      "bounds: (113,207),(203,206),(203,258),(113,259)\n",
      "\n",
      "\"और\"\n",
      "bounds: (225,206),(283,205),(283,256),(225,257)\n",
      "\n",
      "\"इमारतें\"\n",
      "bounds: (303,205),(402,204),(402,256),(303,257)\n",
      "\n",
      "\"हैं\"\n",
      "bounds: (421,205),(445,205),(445,256),(421,256)\n",
      "\n",
      "\",\"\n",
      "bounds: (449,204),(458,204),(458,255),(449,255)\n",
      "\n",
      "\"जिन्हें\"\n",
      "bounds: (486,204),(564,203),(564,254),(486,255)\n",
      "\n",
      "\"देखने\"\n",
      "bounds: (578,203),(659,202),(659,254),(578,255)\n",
      "\n",
      "\"के\"\n",
      "bounds: (688,202),(702,202),(702,253),(688,253)\n",
      "\n",
      "\"लिं\"\n",
      "bounds: (735,202),(760,202),(760,253),(735,253)\n",
      "। दावण म समुद्र क किनार काफी वषा हाता\n",
      "वों में\\nरहती है। भारत के चार प्रमुख महानगर हैं\n",
      "ट और कलकत्ता\\nपूर्वी तट के मुख्य बंदरगाह\n",
      "और चण्डीगढ़ भारत के कुछ अन्य\\nबड़े शहर हैं\n",
      "हीं रहा। यातायात के प्रमुख साधन हैं :\\nरेलगाडि\n",
      "सुन्दर मन्दिर और इमारतें हैं, जिन्हें देखने के लिं\n",
      "\n",
      "lang_hint: ['hi']\n",
      "\n",
      "\"पुलिस ने भागते हुए चोर को पकड़ा।\n",
      "मां ने रोती हुई लड़की को गोद में\n",
      "उठा लिया।\n",
      "वह रेडियो सुनता हुआ आदमी\n",
      "कौन है ?\n",
      "\"\n",
      "bounds: (30,28),(853,28),(853,550),(30,550)\n",
      "\n",
      "\"पुलिस\"\n",
      "bounds: (30,28),(157,28),(157,115),(30,115)\n",
      "\n",
      "\"ने\"\n",
      "bounds: (184,28),(219,28),(219,115),(184,115)\n",
      "\n",
      "\"भागते\"\n",
      "bounds: (245,28),(376,28),(376,115),(245,115)\n",
      "\n",
      "\"हुए\"\n",
      "bounds: (399,28),(464,28),(464,115),(399,115)\n",
      "\n",
      "\"चोर\"\n",
      "bounds: (486,28),(579,28),(579,115),(486,115)\n",
      "\n",
      "\"को\"\n",
      "bounds: (602,28),(665,28),(665,115),(602,115)\n",
      "\n",
      "\"पकड़ा\"\n",
      "bounds: (688,28),(815,28),(815,115),(688,115)\n",
      "\n",
      "\"।\"\n",
      "bounds: (841,28),(853,28),(853,115),(841,115)\n",
      "\n",
      "\"मां\"\n",
      "bounds: (30,160),(87,160),(87,251),(30,251)\n",
      "\n",
      "\"ने\"\n",
      "bounds: (114,160),(149,160),(149,251),(114,251)\n",
      "\n",
      "\"रोती\"\n",
      "bounds: (176,160),(285,160),(285,251),(176,251)\n",
      "\n",
      "\"हुई\"\n",
      "bounds: (310,160),(377,160),(377,251),(310,251)\n",
      "\n",
      "\"लड़की\"\n",
      "bounds: (404,160),(545,160),(545,251),(404,251)\n",
      "\n",
      "\"को\"\n",
      "bounds: (572,160),(633,160),(633,251),(572,251)\n",
      "\n",
      "\"गोद\"\n",
      "bounds: (662,160),(745,160),(745,251),(662,251)\n",
      "\n",
      "\"में\"\n",
      "bounds: (778,160),(809,160),(809,251),(778,251)\n",
      "\n",
      "\"उठा\"\n",
      "bounds: (111,272),(186,268),(189,334),(115,338)\n",
      "\n",
      "\"लिया\"\n",
      "bounds: (208,267),(323,261),(326,327),(212,333)\n",
      "\n",
      "\"।\"\n",
      "bounds: (363,258),(378,257),(382,323),(367,324)\n",
      "\n",
      "\"वह\"\n",
      "bounds: (30,378),(99,378),(99,467),(30,467)\n",
      "\n",
      "\"रेडियो\"\n",
      "bounds: (122,378),(271,378),(271,467),(122,467)\n",
      "\n",
      "\"सुनता\"\n",
      "bounds: (296,378),(433,378),(433,467),(296,467)\n",
      "\n",
      "\"हुआ\"\n",
      "bounds: (458,378),(555,378),(555,467),(458,467)\n",
      "\n",
      "\"आदमी\"\n",
      "bounds: (584,378),(735,378),(735,467),(584,467)\n",
      "\n",
      "\"कौन\"\n",
      "bounds: (100,467),(201,473),(196,543),(96,537)\n",
      "\n",
      "\"है\"\n",
      "bounds: (227,475),(260,477),(256,547),(223,545)\n",
      "\n",
      "\"?\"\n",
      "bounds: (288,479),(307,480),(303,550),(284,549)\n",
      "पुलिस ने भागते हुए चोर को पकड़ा।\n",
      "मां ने रोती हुई लड़की को गोद में\n",
      "उठा लिया।\n",
      "वह रेडियो सुनता हुआ आदमी\n",
      "कौन है ?\n",
      "\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    }
   ],
   "source": [
    "lang_hints_dict = {u'Afrikaans - Afrikaans': \"af\", \n",
    "u'Albanian - shqip': \"sq\", \n",
    "u'Arabic - العربية': \"ar\", \n",
    "u'Armenian - Հայ': \"hy\", \n",
    "u'Belorussian - беларускі': \"be\", \n",
    "u'Bulgarian - български': \"bg\", \n",
    "u'Catalan - Català': \"ca\", \n",
    "u'Chinese - 普通话': \"zh\", \n",
    "u'Croatian - Hrvatski': \"hr\", \n",
    "u'Czech - Čeština': \"cs\", \n",
    "u'Danish - Dansk': \"da\", \n",
    "u'Dutch - Nederlands': \"nl\", \n",
    "u'English  - English': \"en\", \n",
    "u'Estonian - Eesti keel': \"et\", \n",
    "u'Filipino - Filipino': \"fil (or tl)\", \n",
    "u'Finnish - Suomi': \"fi\", \n",
    "u'French  - Français': \"fr\", \n",
    "u'German - Deutsch': \"de\", \n",
    "u'Greek - Ελληνικά': \"el\", \n",
    "u'Gujarati - ગુજરાતી': \"gu\", \n",
    "u'Hebrew - עברית': \"iw\", \n",
    "u'Hindi - हिन्दी': \"hi\", \n",
    "u'Hungarian - Magyar': \"hu\", \n",
    "u'Icelandic - Íslenska': \"is\", \n",
    "u'Indonesian - Bahasa Indonesia': \"id\", \n",
    "u'Italian - Italiano': \"it\", \n",
    "u'Japanese - 日本語': \"ja\", \n",
    "u'Kannada - ಕನ್ನಡ': \"kn\", \n",
    "u'Khmer - ភាសាខ្មែរ': \"km\", \n",
    "u'Korean - 한국어': \"ko\", \n",
    "u'Lao - ລາວ': \"lo\", \n",
    "u'Latvian - Latviešu': \"lv\", \n",
    "u'Lithuanian - Lietuvių': \"lt\", \n",
    "u'Macedonian - Македонски': \"mk\", \n",
    "u'Malay - Bahasa Melayu': \"ms\", \n",
    "u'Malayalam - മലയാളം': \"ml\", \n",
    "u'Marathi - मराठी': \"mr\", \n",
    "u'Nepali - नेपाली': \"ne\", \n",
    "u'Norwegian - Norsk': \"no\", \n",
    "u'Persian - فارسی': \"fa\", \n",
    "u'Polish - Polski': \"pl\", \n",
    "u'Portuguese - Português': \"pt\", \n",
    "u'Punjabi - ਪੰਜਾਬੀ': \"pa\", \n",
    "u'Romanian - Română': \"ro\", \n",
    "u'Russian - Русский': \"ru\", \n",
    "u'Russian - Русский (старая орфография)': \"ru-PETR1708\", \n",
    "u'Serbian - Српски': \"sr\", \n",
    "u'Serbian - Српски (латиница)': \"sr-Latn\", \n",
    "u'Slovak - Slovenčina': \"sk\", \n",
    "u'Slovenian - Slovenščina': \"sl\", \n",
    "u'Spanish - Español': \"es\", \n",
    "u'Swedish - Svenska': \"sv\", \n",
    "u'Tamil - தமிழ்': \"ta\", \n",
    "u'Telugu - తెలుగు': \"te\", \n",
    "u'Thai - ไทย': \"th\", \n",
    "u'Turkish - Türkçe': \"tr\", \n",
    "u'Ukrainian - Українська': \"uk\", \n",
    "u'Vietnamese - Tiếng Việt': \"vi\", \n",
    "u'Yiddish - Yiddish': \"yi\"}\n",
    "\n",
    "class Central(qt_utils.QMainWindow):\n",
    "    def __init__(self, parent=None):\n",
    "        super(Central, self).__init__(parent)\n",
    "        self.pushButton = QPushButton(\"OCR\")\n",
    "        self.pushButton.clicked.connect(self.on_pushButton_clicked)\n",
    "        self.dialogs = list()\n",
    "        self.combo = QComboBox(self)\n",
    "        self.populate_dict(self.combo)\n",
    "        self.codes = set(lang_hints_dict.values())\n",
    "        self.combo.activated.connect(self.handleActivated)\n",
    "        self.lang_hint = []    \n",
    "        self.multiButton = QPushButton(\"OCR Multiple languages\")\n",
    "        self.multiButton.clicked.connect(self.sd)\n",
    "        self.selected = []\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.combo)\n",
    "        layout.addWidget(self.pushButton)\n",
    "        layout.addWidget(self.multiButton)\n",
    "        widget = QWidget()\n",
    "        widget.setLayout(layout)\n",
    "        widget.setFont(QFont('Arial', 11)) \n",
    "        self.setCentralWidget(widget)\n",
    "        self._gui_restore()\n",
    "    \n",
    "    def on_pushButton_clicked(self, mult = False):\n",
    "        if not mult:\n",
    "            self.lang_hint = [lang_hints_dict.get(str(self.combo.currentText()))]\n",
    "        dialog = ocrWidget(self, self.lang_hint)\n",
    "        self.dialogs.append(dialog)\n",
    "        dialog.show()\n",
    "        self.setWindowOpacity(0.)\n",
    "    \n",
    "    def handleActivated(self, index):\n",
    "        self.lang_hint = [self.combo.itemData(index)]\n",
    "        \n",
    "    def populate_dict(self, combo : QComboBox):\n",
    "        for key, value in lang_hints_dict.items():\n",
    "            self.combo.addItem(key, value)\n",
    "            \n",
    "    def sd(self):\n",
    "        info_string = \"\"\"To enter multiple languages, enter the language code in a comma seperate list in order of importance. For example, \n",
    "    if you want to recognize a document with Arabic, English, and French in it, and (Arabic being most and French least important)\n",
    "    enter ar,en,fr. For the full list of language codes see https://cloud.google.com/vision/docs/languages#supported-langs\n",
    "    \"\"\"\n",
    "        text , ok = QInputDialog.getText(self,'InputDialog', info_string)\n",
    "        if ok:\n",
    "            lh = text.replace(\" \", \"\").split(',')\n",
    "            self.lang_hint.clear()\n",
    "            for elem in lh:\n",
    "                if elem not in self.codes:\n",
    "                    print(\"the language code {0} cannot be found! check your codes!\".format(elem))\n",
    "                    return\n",
    "                else:\n",
    "                    self.lang_hint.append(elem)\n",
    "            self.on_pushButton_clicked(True)\n",
    "\n",
    "    \n",
    "def main():\n",
    "    app = QtCore.QCoreApplication.instance()\n",
    "    if app is None:\n",
    "        app = QApplication(sys.argv)\n",
    "    main = Central()\n",
    "    main.show()\n",
    "    sys.exit(app.exec_())\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#somehow remeber the favorite langs selected\n",
    "#create keyboard shorcuts??\n",
    "#consider logic for setting multuple lang hints (i.e. checkbox) \n",
    "#settings menu to set quick access langs i.e. english, spanish, french "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'उत्तर से कम । दक्षिण में समुद्र के किनारे काफ़ी वर्षा होती है और पैदावार अच्छी होती\\nहै।\\nयह\\nभारत एक कृषि प्रधान देश है और देश की लगभग ७० प्रतिशत आबादी गाँवों में\\nरहती है। भारत के चार प्रमुख महानगर हैं: नई दिल्ली, बम्बई, कलकत्ता और मद्रास ।\\nभारत की राजधानी, नई दिल्ली, उत्तर में स्थित है। बम्बई पश्चिमी तट और कलकत्ता\\nपूर्वी तट के मुख्य बंदरगाह हैं। मद्रास दक्षिण का सबसे बड़ा शहर है और भी\\nसमुद्र\\nके\\nकिनारे बसा है। बंगलोर, हैदराबाद, लखनऊ, जयपुर और चण्डीगढ़ भारत के कुछ अन्य\\nबड़े शहर हैं। सबसे पुराना शहर वाराणसी, या बनारस, गंगा के तट पर बसा है।\\nभारत में सफर करना अब बहुत मुश्किल नहीं रहा। यातायात के प्रमुख साधन हैं :\\nरेलगाड़ियाँ और सड़कें। आजकल हम काफ़ी शहरों को हवाई जहाज़ से भी जा सकते हैं ।\\nभारत में प्राचीन काल के बहुत सुन्दर मन्दिर और इमारतें हैं, जिन्हें देखने के लिए दूर-दूर\\nसे लोग आते हैं । अजंता और एलोरा की गुफाएँ और आगरे का ताजमहल तो सारी दुनिया\\nमें प्रसिद्ध हैं।\\nभारत ने १५ अगस्त १९४७ को इंगलैंड से स्वतंत्रता पाई और २६ जनवरी १९५० को\\nइसका संविधान लागू हुआ । भारत के विभिन्न प्रदेशों में अलग-अलग परंपराएँ, भाषाएँ,\\nवेशभूषा और तरह-तरह का खाना मिलता है । भारतीय संविधान के अनुसार भारत एक\\nधर्म-निरपेक्ष देश है। यहाँ अनेक धर्मों के लोग रहते हैं । भारत में चौदह प्रमुख भाषाएँ\\nबोली जाती हैं लेकिन हिन्दी देश की राष्ट्रभाषा है।\\n2\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtlh(r\"C:\\Users\\poorv\\Downloads\\hindi\\१००A\\hw4\\Pages from Intermediate Hindi Reader (Hindi and English Edition)  _Page_2.png\", [\"hi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_file(speech_file):\n",
    "    \"\"\"Transcribe the given audio file asynchronously.\"\"\"\n",
    "    from google.cloud import speech\n",
    "\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(speech_file, \"rb\") as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = speech.RecognitionAudio(content=content)\n",
    "    config = speech.RecognitionConfig(\n",
    "        encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=16000,\n",
    "        language_code=\"hi-IN\",\n",
    "    )\n",
    "\n",
    "    operation = client.long_running_recognize(\n",
    "        request={\"config\": config, \"audio\": audio}\n",
    "    )\n",
    "\n",
    "    print(\"Waiting for operation to complete...\")\n",
    "    response = operation.result(timeout=120)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u\"Transcript: {}\".format(result.alternatives[0].transcript))\n",
    "        print(\"Confidence: {}\".format(result.alternatives[0].confidence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sam = r\"C:\\Users\\poorv\\Downloads\\hindi\\१००A\\hw5\\01_11_Goswamy.flac\"\n",
    "\n",
    "image.source.image_uri = \"gs://boocket_head/audios/01_11_Vijay.flac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'https://storage.cloud.google.com/boocket_head/audios/01_11_Vijay.flac?authuser=3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7866bea96fd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranscribe_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"https://storage.cloud.google.com/boocket_head/audios/01_11_Vijay.flac?authuser=3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-1e9f68d7cbe1>\u001b[0m in \u001b[0;36mtranscribe_file\u001b[1;34m(speech_file)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'https://storage.cloud.google.com/boocket_head/audios/01_11_Vijay.flac?authuser=3'"
     ]
    }
   ],
   "source": [
    "transcribe_file(\"https://storage.cloud.google.com/boocket_head/audios/01_11_Vijay.flac?authuser=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "recognize() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-c4e1ff04b819>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'language_code'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'hi-IN'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0maudio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'uri'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'gs://boocket_head/audios/01_11_Vijay.flac'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mspeech_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-c4e1ff04b819>\u001b[0m in \u001b[0;36mspeech_to_text\u001b[1;34m(config, audio)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspeech_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: recognize() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from google.cloud import speech_v1 as speech\n",
    "\n",
    "\n",
    "def speech_to_text(config, audio):\n",
    "    client = speech.SpeechClient()\n",
    "    response = client.recognize(config, audio)\n",
    "    print_sentences(response)\n",
    "\n",
    "\n",
    "def print_sentences(response):\n",
    "    for result in response.results:\n",
    "        best_alternative = result.alternatives[0]\n",
    "        transcript = best_alternative.transcript\n",
    "        confidence = best_alternative.confidence\n",
    "        print('-' * 80)\n",
    "        print(f'Transcript: {transcript}')\n",
    "        print(f'Confidence: {confidence:.0%}')\n",
    "\n",
    "\n",
    "config = {'language_code': 'hi-IN'}\n",
    "audio = {'uri': 'gs://boocket_head/audios/01_11_Vijay.flac'}\n",
    "speech_to_text(config, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "recognize() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-e98bdfbf0a3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspeech_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-94f151c47b91>\u001b[0m in \u001b[0;36mspeech_to_text\u001b[1;34m(config, audio)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mspeech_to_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecognize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maudio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprint_sentences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: recognize() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "speech_to_text(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'gs://boocket_head/audios/01_11_Vijay.flac'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-aa24a441155f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranscribe_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uri'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-1e9f68d7cbe1>\u001b[0m in \u001b[0;36mtranscribe_file\u001b[1;34m(speech_file)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudio_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'gs://boocket_head/audios/01_11_Vijay.flac'"
     ]
    }
   ],
   "source": [
    "transcribe_file(c2['uri'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_transcribe(audio_file_name):\n",
    "    \n",
    "    file_name = filepath + audio_file_name\n",
    "    mp3_to_wav(file_name)\n",
    "\n",
    "    # The name of the audio file to transcribe\n",
    "    \n",
    "    frame_rate, channels = frame_rate_channel(file_name)\n",
    "    \n",
    "    if channels > 1:\n",
    "        stereo_to_mono(file_name)\n",
    "    \n",
    "    bucket_name = bucketname\n",
    "    source_file_name = filepath + audio_file_name\n",
    "    destination_blob_name = audio_file_name\n",
    "    \n",
    "    upload_blob(bucket_name, source_file_name, destination_blob_name)\n",
    "    \n",
    "    gcs_uri = 'gs://' + bucketname + '/' + audio_file_name\n",
    "    transcript = ''\n",
    "    \n",
    "    client = speech.SpeechClient()\n",
    "    audio = types.RecognitionAudio(uri=gcs_uri)\n",
    "\n",
    "    config = types.RecognitionConfig(\n",
    "    encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "    sample_rate_hertz=frame_rate,\n",
    "    language_code='en-US',\n",
    "    enable_speaker_diarization=True,\n",
    "    diarization_speaker_count=2) #Changed\n",
    "\n",
    "    # Detects speech in the audio file\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "    response = operation.result(timeout=10000)\n",
    "    result = response.results[-1] #Changed\n",
    "    words_info = result.alternatives[0].words #Changed\n",
    "    \n",
    "    tag=1 #Changed\n",
    "    speaker=\"\" #Changed\n",
    "\n",
    "    for word_info in words_info: #Changed\n",
    "        if word_info.speaker_tag==tag: #Changed\n",
    "            speaker=speaker+\" \"+word_info.word #Changed\n",
    "        else: #Changed\n",
    "            transcript += \"speaker {}: {}\".format(tag,speaker) + '\\n' #Changed\n",
    "            tag=word_info.speaker_tag #Changed\n",
    "            speaker=\"\"+word_info.word #Changed\n",
    " \n",
    "    transcript += \"speaker {}: {}\".format(tag,speaker) #Changed\n",
    "    \n",
    "    delete_blob(bucket_name, destination_blob_name)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-5e9e88c2913f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgoogle_transcribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-843343cd7017>\u001b[0m in \u001b[0;36mgoogle_transcribe\u001b[1;34m(audio_file_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgoogle_transcribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maudio_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0maudio_file_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mmp3_to_wav\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filepath' is not defined"
     ]
    }
   ],
   "source": [
    "google_transcribe(sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://storage.cloud.google.com/boocket_head/audios/01_11_Vijay.flac?authuser=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [START speech_transcribe_async_gcs]\n",
    "def transcribe_gcs(gcs_uri):\n",
    "    \"\"\"Asynchronously transcribes the audio file specified by the gcs_uri.\"\"\"\n",
    "    from google.cloud import speech\n",
    "    from google.cloud.speech_v1 import enums\n",
    "    from google.cloud.speech_v1 import types\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    audio = types.RecognitionAudio(uri=gcs_uri)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.FLAC,\n",
    "        sample_rate_hertz=48000,\n",
    "        language_code='de-DE')\n",
    "\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "\n",
    "    print('Transcribing your cloud-stored audio file...')\n",
    "    response = operation.result(timeout=1800)\n",
    "\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        print(u'Transcript: {}'.format(result.alternatives[0].transcript))\n",
    "        print('Confidence: {}'.format(result.alternatives[0].confidence))\n",
    "# [END speech_transcribe_async_gcs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ud = \"gs://boocket_head/audios/01_11_Vijay.flac\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'enums' from 'google.cloud.speech_v1' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\cloud\\speech_v1\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-8f9e5de9c754>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtranscribe_gcs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mud\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-9002c0980999>\u001b[0m in \u001b[0;36mtranscribe_gcs\u001b[1;34m(gcs_uri)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m\"\"\"Asynchronously transcribes the audio file specified by the gcs_uri.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeech_v1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0menums\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspeech_v1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mclient\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspeech\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpeechClient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'enums' from 'google.cloud.speech_v1' (C:\\ProgramData\\Anaconda3\\lib\\site-packages\\google\\cloud\\speech_v1\\__init__.py)"
     ]
    }
   ],
   "source": [
    "transcribe_gcs(ud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print(string):\n",
    "    split = string.split()\n",
    "    print(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
